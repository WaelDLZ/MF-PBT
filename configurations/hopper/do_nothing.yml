env_name: 'hopper'
backend: 'positional'

num_rounds: 1000
num_timesteps_round: 1_000_000

num_envs_per_agent: 1024
num_agents: 24
numpy_seed: 0
jax_seed: 0

logging_directory: null

training_config:
  unroll_length: 10
  episode_length: 1_000
  num_envs: 64
  num_minibatches: 32
  batch_size: 1024
  num_updates_per_batch: 8
  num_eval_envs: 512
  num_evals: 2
  deterministic_eval: True
  normalize_advantage: True

hpo_search_space:


default_hps:
  learning_rate: 0.0003
  entropy_cost: 0.001
  discounting: 0.997
  clipping_epsilon: 0.2
  gae_lambda: 0.95
  reward_scaling: 30

routines:
  explore:

  exploit:
    function_name: 'random_search_exploitation'
    function_param :
      arg: 0
